Metadata-Version: 2.4
Name: customer-support-agent-backend
Version: 0.1.0
Summary: AI-ready backend API for customer-support-agent
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.111.0
Requires-Dist: uvicorn[standard]>=0.30.0
Requires-Dist: pydantic-settings>=2.3.0
Requires-Dist: httpx>=0.27.0
Requires-Dist: openai>=1.40.0
Requires-Dist: google-generativeai>=0.8.0
Provides-Extra: dev
Requires-Dist: pytest>=8.0; extra == "dev"
Requires-Dist: mypy>=1.10; extra == "dev"
Requires-Dist: ruff>=0.5; extra == "dev"

# Backend

Python FastAPI backend for `customer-support-agent`.

## Structure

- `app/api/routes`: route handlers (`health`, `search`, `jsonplaceholder`, `llm`)
- `app/api/schemas`: API schemas
- `app/clients`: external API clients
- `app/services`: business services
- `app/services/llm`: provider abstraction (`base`, `factory`, `openai_provider`, `gemini_provider`)
- `app/orchestration`: orchestration layer
- `app/core`: config, errors, deps, protocols, logging

## Setup (uv)

```bash
cp .env.example .env
uv sync --extra dev
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## AI defaults

- `LLM_PROVIDER`: `openai` or `gemini`
- `LLM_MODEL`: optional override (auto-default per provider)
- `OPENAI_API_KEY` and `GEMINI_API_KEY` available by default in settings
- `GET /api/llm/config` returns the active provider/model configuration
